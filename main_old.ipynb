{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Neural Inverted Index for Fast and Effective Information Retrieval\n",
        "\n",
        "---\n",
        "\n",
        "## üìö Notebook Overview\n",
        "\n",
        "This notebook explores a novel [information retrieval (IR)](https://en.wikipedia.org/wiki/Information_retrieval) framework that utilizes a **differentiable function** to generate a **sorted list of document identifiers** in response to a given **query**.\n",
        "\n",
        "The approach is called **Differentiable Search Index (DSI)**, and was originally proposed in the paper [Transformer Memory as a Differentiable Search Index](https://arxiv.org/pdf/2202.06991.pdf) by researchers at Google Research.\n",
        "\n",
        "**DSI** aims at both encompassing all document's corpus information and executing retrieval within a single **Transformer language model**, instead of adopting the index-then-retrieve pipeline used in most modern IR sytems.\n",
        "\n",
        "The notebook presents the implemented solution, a **Sequence to Sequence transformer** model `f` that, given a query `q` as input, returns a list of document IDs ranked by relevance to the query, and compares its performance with the traditional **TF-IDF** retrieval model, a **Word2Vec** model, and a **Siamese Network model with Triplet Loss**.\n",
        "\n",
        "The proposed solution combines the **DSI** approach with the **Scheduled Sampling** technique for Transformers, inspired by the similar technique described in the paper [Scheduled Sampling for Transformers](https://arxiv.org/abs/1906.07651).\n",
        "\n",
        "We evaluate the performance of the proposed models using the **Mean Average Precision (MAP)** and the **Recall at K** metrics computed on the **MS MARCO** dataset, and we compare the results with several baselines (**TF-IDF**, **Word2Vec**, **Siamese Network** and also other traditional **Transformer** approaches).\n",
        "\n",
        "## üìù Author\n",
        "\n",
        "**Valerio Di Stefano** - _\"Sapienza\" University of Rome_\n",
        "<br/>\n",
        "Email: [distefano.1898728@studenti.uniroma1.it](mailto:distefano.1898728@studenti.uniroma1.it)\n",
        "\n",
        "## üîó External Links\n",
        "\n",
        "* **Main Paper**: [Transformer Memory as a Differentiable Search Index](https://arxiv.org/pdf/2202.06991.pdf)\n",
        "\n",
        "  _Authors_: Yi Tay, Vinh Q. Tran, Mostafa Dehghani, Jianmo Ni, Dara Bahri, Harsh Mehta, Zhen Qin, Kai Hui, Zhe Zhao, Jai Gupta, Tal Schuster, William W. Cohen, Donald Metzler\n",
        "\n",
        "* **Relevant Paper**: [Understanding Differential Search Index for Text Retrieval](https://arxiv.org/abs/2305.02073)\n",
        "\n",
        "  _Authors_: Xiaoyang Chen, Yanjiang Liu, Ben He, Le Sun, Yingfei Sun\n",
        "\n",
        "* **Relevant Paper**: [Scheduled Sampling for Transformers](https://arxiv.org/abs/1906.07651)\n",
        "\n",
        "\t_Authors_: Tsvetomila Mihaylova, Andr√© F. T. Martins\n",
        "\n",
        "* **Project Repository**: [GitHub Repository](https://github.com/valeriodiste/deep_learning_project)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8zL3Fr68W7QG"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## üìå Table of Contents\n",
        "\n",
        "To do...\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGdCNyGIW7QH"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "\n",
        "<a id=\"1\"></a>\n",
        "# üöÄ Getting Started\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9KwLmmxOW7QH"
      },
      "source": [
        "First of all, we check if we are running the notebook on Google colab or locally, defining the `RUNNING_ON_COLAB` constant used throughout the notebook."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jnFvNpE-W7QH"
      },
      "outputs": [],
      "source": [
        "# Check if running on colab or locally\n",
        "try:\n",
        "\tfrom google.colab import files\n",
        "\tRUNNING_IN_COLAB = True\n",
        "\tprint(\"Running on Google Colab.\")\n",
        "except ModuleNotFoundError:\n",
        "\tRUNNING_IN_COLAB = False\n",
        "\tprint(\"Running locally.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "<a id=\"1_1\"></a>\n",
        "## Collect Source Files\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Clone Project's GitHub Repository\n",
        "\n",
        "We **clone the project's repository** from GitHub to access the source files for datasets, models, evaluation and utilities.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4hK7QNbYW7QI"
      },
      "outputs": [],
      "source": [
        "# Clone the git repository of the project for the source files\n",
        "!git clone https://github.com/valeriodiste/computer_vision_project_dev.git\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Pull Latest Files Changes\n",
        "\n",
        "We also **pull the latest changes** from the repository and store them in the `./computer_vision_project` directory.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uTO-K52dW7QI"
      },
      "outputs": [],
      "source": [
        "# Change the working directory to the cloned repository\n",
        "# TO DO: change the directory to the correct one\n",
        "%cd /content/computer_vision_project_dev\n",
        "# Pull the latest changes from the repository\n",
        "!git pull origin main\n",
        "# Change the working directory to the parent directory\n",
        "%cd .."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"1_2\"></a>\n",
        "## Install & Import Libraries"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Install Libraries\n",
        "\n",
        "We **install all the necessary libraries** for this notebook.\n",
        "\n",
        "- **`pytorch-lightning`**: A **lightweight PyTorch wrapper** for simplifying PyTorch code.\n",
        "- **`ir_datasets`**: A Python library for accessing **information retrieval datasets** (used to load the **\"MS MARCO\" dataset**).\n",
        "- **`wandb`**: The python package for **Weights & Biases**, a tool for experiment tracking, dataset versioning, and project collaboration (used for **logging and visualization**)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3AgkA542W7QI"
      },
      "outputs": [],
      "source": [
        "# Install the required packages\n",
        "%%capture\n",
        "%pip install pytorch-lightning\n",
        "%pip install pycocotools\n",
        "%pip install wandb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Import Modules\n",
        "\n",
        "We then **import the required modules**, including `PyTorch`, `PyTorch Lightning`, `IR Datasets` and `W&B`, plus other useful modules and libraries (`NLTK`, `Scikit Learn`, `Numpy`, `Pandas`, etc...)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYzvoExIW7QJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Import the standard libraries\n",
        "import os\n",
        "import json\n",
        "import random\n",
        "import logging\n",
        "import math\n",
        "\n",
        "# Import the PyTorch libraries and modules\n",
        "import torch\n",
        "\n",
        "# Import the PyTorch Lightning libraries and modules\n",
        "import pytorch_lightning as pl\n",
        "\n",
        "# Import the coco library\n",
        "from pycocotools.coco import COCO\n",
        "\n",
        "# Import the W&B (Weights & Biases) library\n",
        "# import wandb\n",
        "# from wandb.sdk import wandb_run\n",
        "# from pytorch_lightning.loggers import WandbLogger\n",
        "\n",
        "# Other libraries\n",
        "import numpy as np\n",
        "import skimage.io as io\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "\n",
        "# Import the tqdm library (for the progress bars)\n",
        "if not RUNNING_IN_COLAB:\n",
        "\tfrom tqdm import tqdm\n",
        "else:\n",
        "\tfrom tqdm.notebook import tqdm\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aS7SbDJlW7QJ"
      },
      "source": [
        "We also import our own **custom modules** (cloned from the repository) containing Python classes for **datasets**, **models**, **evaluation**, and **utilities**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "k0Zq6ypFW7QJ"
      },
      "outputs": [],
      "source": [
        "# Import the custom modules\n",
        "if not RUNNING_IN_COLAB:\n",
        "\t# We are running locally (not on Google Colab, import modules from the \"src\" directory in the current directory)\n",
        "\tfrom src.scripts import models, datasets, training, evaluation\n",
        "\tfrom src.scripts.utils import (\n",
        "\t\tprint_json, RANDOM_SEED, print_model_evaluation_results, MODEL_CHECKPOINT_FILE\n",
        "\t)\n",
        "else:\n",
        "\t# We are running on Google Colab (import modules from the pulled repository stored in the project's directory)\n",
        "\tfrom computer_vision_project_dev.src.scripts import models, datasets, training, evaluation\n",
        "\tfrom computer_vision_project_dev.src.scripts.utils import (\n",
        "\t\tprint_json, RANDOM_SEED, print_model_evaluation_results, MODEL_CHECKPOINT_FILE\n",
        "\t)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"1_3\"></a>\n",
        "## Configuration, Hyperparameters and Constants"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Random Seed\n",
        "\n",
        "We **seed the random number generators** for reproducibility."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G6-mmMEmW7QJ"
      },
      "outputs": [],
      "source": [
        "# Set the random seeds for reproducibility\n",
        "random.seed(RANDOM_SEED)\n",
        "torch.manual_seed(RANDOM_SEED)\n",
        "pl.seed_everything(RANDOM_SEED)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Device Configuration\n",
        "\n",
        "We **set the device** to GPU if available, otherwise we use the CPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6cgGByHAW7QJ"
      },
      "outputs": [],
      "source": [
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Device: {device.type}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Database Constants\n",
        "\n",
        "We **define the constants** used for the **database resources download** and the **dataset creation**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-mNAOE_W7QJ"
      },
      "outputs": [],
      "source": [
        "# TO DO..."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Models Hyperparameters\n",
        "\n",
        "We then **define the constant** representing **hyperparameters** used for the **Word2Vec model**, the **Siamese Network model** and for the **Seq2Seq transformer model**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oVuO8Fe7W7QK"
      },
      "outputs": [],
      "source": [
        "# Define the max length of the tokenized queries and documents for the Transformer model (embeddings will be padded or truncated to this length)\n",
        "TRANSFORMER_DOCUMENT_MAX_TOKENS = 64\n",
        "TRANSFORMER_QUERY_MAX_TOKENS = 32\n",
        "\n",
        "# Define the size of the embeddings for the Encoders of the Seq2Seq Transformer model\n",
        "TRANSFORMER_EMBEDDINGS_SIZE = 128"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Evauation Constants\n",
        "\n",
        "We also define the constants used for the evaluation of the various models (i.e. to compute the **Mean Average Precision** and the **Recall at K**)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p3z312t5W7QK"
      },
      "outputs": [],
      "source": [
        "# Define the number of documents K to retrieve for each query and the number of queries N to calculate the mean average precision (MAP@K)\n",
        "MAP_K = 10\n",
        "MAP_N = 10\n",
        "\n",
        "# Define the number of documents K to retrieve for each query to calculate the Recall@K metrics\n",
        "RECALL_K = 1_000\n",
        "\n",
        "# Whether to print the debug information during the MAP@K and Recall@K evaluation of the models\n",
        "PRINT_EVALUATION_DEBUG = True\n",
        "\n",
        "# Whether to evaluate the models (i.e. compute the MAP@K and Recall@K metrics for the trained models on the test datasets)\n",
        "EVALUATE_MODELS = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Other Constants\n",
        "\n",
        "We ultimately define the constants used to determine where to save data and models and the flags to enable/disable database rebuild/refresh and the loading of models checkpoints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NFo3Xe4MW7QK"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Define the data folder, onto which the documents and queries dictionaries will be saved\n",
        "DATA_FOLDER = \"src/data\" if not RUNNING_IN_COLAB else \"/content/data\"\n",
        "\n",
        "# Define the path to save models\n",
        "MODELS_FOLDER = \"src/models\" if not RUNNING_IN_COLAB else \"/content/models\"\n",
        "\n",
        "# Whether to load model checkpoints (if they were already saved locally) or not\n",
        "LOAD_MODELS_CHECKPOINTS = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Local Files Folder Creation\n",
        "\n",
        "We create the folders to store the data dictionaries and the model's checkpoints."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Chyt_ybzW7QK"
      },
      "outputs": [],
      "source": [
        "# Create folders if they do not exist\n",
        "if not os.path.exists(DATA_FOLDER):\n",
        "\tprint(f\"Creating the data folder at '{DATA_FOLDER}'...\")\n",
        "\tos.makedirs(DATA_FOLDER)\n",
        "if not os.path.exists(MODELS_FOLDER):\n",
        "\tprint(f\"Creating the models folder at '{MODELS_FOLDER}'...\")\n",
        "\tos.makedirs(MODELS_FOLDER)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Weights & Biases Configuration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i9_xNrpcW7QL"
      },
      "source": [
        "We set the **Weights & Biases** API key to log the experiments.\n",
        "\n",
        "**‚ö†Ô∏è Note**: Copy and paste your own W&B API key into the `WANDB_API_KEY` constant to see logging results, or set the constant to an empty string to disable W&B logging (this won't plot training losses and accuracies over time)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YVM3l8IcW7QL"
      },
      "outputs": [],
      "source": [
        "# Define the WANDB_API_KEY (set to \"\" to disable W&B logging)\n",
        "# NOTE: leaving the WANDB_API_KEY to a value of None will throw an error\n",
        "WANDB_API_KEY = \"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1EYR8RRW7QL"
      },
      "source": [
        "We configure the **Weights & Biases** logger and API to track the experiments and the model's performances."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QVXlI87xW7QL"
      },
      "outputs": [],
      "source": [
        "# Define the wandb logger, api object, entity name and project name\n",
        "wandb_logger = None\n",
        "wandb_api = None\n",
        "wandb_entity = None\n",
        "wandb_project = None\n",
        "# Check if a W&B api key is provided\n",
        "if WANDB_API_KEY == None:\n",
        "\tprint(\"No W&B API key provided, please provide a valid key to use the W&B API or set the WANDB_API_KEY variable to an empty string to disable logging\")\n",
        "\traise ValueError(\"No W&B API key provided.\")\n",
        "elif WANDB_API_KEY != \"\":\n",
        "\t# Login to the W&B (Weights & Biases) API\n",
        "\twandb.login(key=WANDB_API_KEY, relogin=True)\n",
        "\t# Minimize the logging from the W&B (Weights & Biases) library\n",
        "\tos.environ[\"WANDB_SILENT\"] = \"true\"\n",
        "\tlogging.getLogger(\"wandb\").setLevel(logging.ERROR)\n",
        "\t# Initialize the W&B (Weights & Biases) loggger\n",
        "\twandb_logger = WandbLogger(\n",
        "\t\tlog_model=\"all\", project=\"cv-dsi-project\", name=\"- SEPARATOR -\")\n",
        "\t# Initialize the W&B (Weights & Biases) API\n",
        "\twandb_api = wandb.Api()\n",
        "\t# Get the W&B (Weights & Biases) entity name\n",
        "\twandb_entity = wandb_logger.experiment.entity\n",
        "\t# Get the W&B (Weights & Biases) project name\n",
        "\twandb_project = wandb_logger.experiment.project\n",
        "\t# Finish the \"separator\" experiment\n",
        "\twandb_logger.experiment.finish(quiet=True)\n",
        "\tprint(\"W&B API key provided, logging with W&B enabled.\")\n",
        "else:\n",
        "\tprint(\"No W&B API key provided, logging with W&B disabled.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"1_4\"></a>\n",
        "## Download Data & Resources"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Download Datasets\n",
        "\n",
        "TO DO..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cABdiHNGW7QM"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Download the pytorch vision datasets\n",
        "# Define the data folder for the datasets\n",
        "DATA_FOLDER = \"src/data\" if not RUNNING_IN_COLAB else \"/content/data\"\n",
        "\n",
        "# Define the datasets to download\n",
        "# NOTE: use a dataset for image captioning (only one in pythorch vision is COCO) or image classification (e.g. CIFAR-10, CIFAR-100, etc.):\n",
        "# - Image captioning:\t\thttps://pytorch.org/vision/main/datasets.html#image-captioning\n",
        "# - Image classification:\thttps://pytorch.org/vision/main/datasets.html#image-classification\n",
        "DATASET = \"coco\"  # \"coco\", \"cifar10\", \"cifar100\", etc...\n",
        "\n",
        "\n",
        "# Example on the use of the coco dataset with python  (not using the pyrorch vision coco dataset)\n",
        "# > https://www.kaggle.com/code/visheshvats/image-caption-generation-on-coco-dataset-ipynb\n",
        "# Official pycocotools notebook demo file here:\n",
        "# > https://github.com/cocodataset/cocoapi/blob/master/PythonAPI/pycocoDemo.ipynb\n",
        "\n",
        "\n",
        "'''\n",
        "# Download the MS MARCO dataset (if needed and if the dictionaries need to be built/rebuilt)\n",
        "if FORCE_DICTIONARIES_REBUILD or not os.path.exists(DATA_FOLDER + \"/docs_dict.json\") or not os.path.exists(DATA_FOLDER + \"/queries_dict.json\"):\n",
        "\n",
        "\t# Load the MS MARCO dataset\n",
        "\tdataset = None\n",
        "\tif USE_DOCUMENTS_DATASETS:\n",
        "\t\t# Load https://ir-datasets.com/msmarco-passage.html#msmarco-document/dev\n",
        "\t\tdataset = ir_datasets.load(\"msmarco-document/dev\")\n",
        "\telse:\n",
        "\t\t# Load https://ir-datasets.com/msmarco-passage.html#msmarco-passage/dev/small\n",
        "\t\tdataset = ir_datasets.load(\"msmarco-passage/dev/small\")\n",
        "\n",
        "\t# Triggers the download of the datasets (if not already downloaded)\n",
        "\tdataset.docs_iter().__next__()\n",
        "\tdataset.queries_iter().__next__()\n",
        "\tdataset.qrels_iter().__next__()\n",
        "\tdataset.scoreddocs_iter().__next__()\n",
        "\n",
        "\t# Print the dataset structure (i.e. the column names)\n",
        "\tprint_metadata = False\n",
        "\tif print_metadata:\n",
        "\t\tprint(\"Docs Metadata:\")\n",
        "\t\tprint_json(dataset.docs_metadata(), 2)\n",
        "\t\tprint(\"Queries Metadata:\")\n",
        "\t\tprint_json(dataset.queries_metadata(), 2)\n",
        "\t\tprint(\"Qrels Metadata:\")\n",
        "\t\tprint_json(dataset.qrels_metadata(), 2)\n",
        "\t\tprint(\"Scored Docs Metadata:\")\n",
        "\t\tprint_json(dataset.scoreddocs_metadata(), 2)\n",
        "\n",
        "\t# Print some samples of the dataset\n",
        "\tprint_database_samples = False\n",
        "\tif print_database_samples:\n",
        "\t\t# Print a sample document\n",
        "\t\tprint(\"\\nSample Document:\")\n",
        "\t\tprint(\"  <doc_id, url, title, body>\"\n",
        "\t\t\t  if USE_DOCUMENTS_DATASETS\n",
        "\t\t\t  else \"  <doc_id, text>\")\n",
        "\t\tdoc = dataset.docs_iter().__next__()\n",
        "\t\tprint_json(doc, 2)\n",
        "\t\t# Print a sample query\n",
        "\t\tprint(\"\\nSample Query:\")\n",
        "\t\tprint(\"  <query_id, text>\")\n",
        "\t\tquery = dataset.queries_iter().__next__()\n",
        "\t\tprint_json(query, 2)\n",
        "\t\t# Print a sample qrel\n",
        "\t\t#   NOTE: the \"relevance\" and \"iteration\" fields are always 1 and \"0\" respectively, for all the qrels (qrels only contain relevant pairs of <query_id, doc_id>)\n",
        "\t\tprint(\"\\nSample Qrel:\")\n",
        "\t\tprint(\"  <query_id, doc_id, relevance, iteration>\")\n",
        "\t\tqrel = dataset.qrels_iter().__next__()\n",
        "\t\tprint_json(qrel, 2)\n",
        "\t\t# Print a sample scored doc\n",
        "\t\tprint(\"\\nSample Scored Doc:\")\n",
        "\t\tprint(\"  <query_id, doc_id, score>\")\n",
        "\t\tscored_doc = dataset.scoreddocs_iter().__next__()\n",
        "\t\tprint_json(scored_doc, 2)\n",
        "else:\n",
        "\t# Print a message indicating that the dictionaries already exist and will be loaded\n",
        "\tprint(\"No need to download the MS MARCO dataset.\")\n",
        "\tprint(\"Documents and queries dictionaries already exist and will be loaded from the JSON files.\")\n",
        "'''\n",
        "\t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OK82SdaDW7QM"
      },
      "source": [
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "<a id=\"2\"></a>\n",
        "# üíæ Data Preparation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Data Variables and Constants\n",
        "\n",
        "We define the `docs_dict` and `queries_dict` dictionaries used to store the documents and queries data.\n",
        "\n",
        "The `docs_dict` dictionary contains, for each document ID, the documents' text and its Word2Vec embedding.\n",
        "\n",
        "The `queries_dict` dictionary contains, for each query ID, the query's text, its Word2Vec embedding and also the list of document IDs for documents relevant to the query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hJypxBvsW7QM"
      },
      "outputs": [],
      "source": [
        "# Dictionaries to store the documents and queries (the main dataset)\n",
        "docs_dict = {}\n",
        "queries_dict = {}\n",
        "\n",
        "# Auxiliary dictionary to map the column names to the corresponding index in the ir_datasets tuples\n",
        "IR_DATASET_COLS = {\n",
        "\t\"DOCS\": {\"id\": 0, \"url\": 1, \"title\": 2, \"body\": 3} if USE_DOCUMENTS_DATASETS else {\"id\": 0, \"text\": 1},\n",
        "\t\"QUERIES\": {\"id\": 0, \"text\": 1},\n",
        "\t\"QRELS\": {\"query_id\": 0, \"doc_id\": 1},\n",
        "\t\"SCORED_DOCS\": {\"query_id\": 0, \"doc_id\": 1, \"score\": 2}\n",
        "}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"2_1\"></a>\n",
        "## Word2Vec Model Initialization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaYMRsxLW7QM"
      },
      "source": [
        "We initialize the `Word2Vec` model to compute the **vector embeddings** of the documents and queries.\n",
        "\n",
        "This model is later **trained on the documents corpus** (using the `Gensim` library) to output vector embeddings of size `VECTOR_EMBEDDINGS_SIZE` for documents and queries.\n",
        "\n",
        "This model is also used as a **baseline** for the evaluation of the final **Seq2Seq** transformer model (we compute the cosine similarity of the output embeddings between a query and the entire documents database to generate the top `K` most relevant documents)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9UzNkQReW7QM"
      },
      "outputs": [],
      "source": [
        "# Initialize a Word2Vec model to encode the text\n",
        "word2vec_model = models.Word2VecModel(\n",
        "\tembeddings_size=VECTOR_EMBEDDINGS_SIZE,\n",
        "\twords_window_size=10,\n",
        "\tmin_word_frequency=0,\n",
        "\tlearning_rate=0.025,\n",
        "\tmax_epochs=20,\n",
        "\tsave_path=MODELS_FOLDER + \"/\" +\n",
        "\tMODEL_CHECKPOINTS_FILES[MODEL_TYPES.WORD2VEC]\n",
        ")\n",
        "\n",
        "\n",
        "def load_or_train_word2vec_model(documents_corpus=None):\n",
        "\t'''\n",
        "\tTrain the word2vec model if the checkpoint file does not exist, otherwise load the model from the checkpoint file\n",
        "\n",
        "\tIf document_corpus is None or is an empty list, a new document corpus will be created using the documents in the dataset\n",
        "\n",
        "\tIf a document_corpus is provided (as a list of list of strings representing the words of each document's text), it will be used to train the Word2Vec model\n",
        "\t'''\n",
        "\tloaded_checkpoint = False\n",
        "\tif LOAD_MODELS_CHECKPOINTS:\n",
        "\t\tloaded_checkpoint = word2vec_model.load()\n",
        "\tif not loaded_checkpoint:\n",
        "\t\t# Train the Word2Vec model on the documents corpus\n",
        "\t\tprint(\"Training the Word2Vec model on the documents corpus...\")\n",
        "\t\tif documents_corpus is None or len(documents_corpus) == 0:\n",
        "\t\t\t# Build the documents corpus\n",
        "\t\t\tdocuments_corpus = [get_preprocessed_text(\n",
        "\t\t\t\tdocs_dict[doc_id][\"text\"]).split(\" \") for doc_id in docs_dict]\n",
        "\t\t# Train the Word2Vec model\n",
        "\t\tword2vec_model.train(documents_corpus)\n",
        "\t\tprint(\"Word2Vec model training completed.\")\n",
        "\telse:\n",
        "\t\tprint(\"Word2Vec model loaded from the checkpoint file.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"2_2\"></a>\n",
        "\n",
        "## Dictionaries Creation & Word2Vec Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JfYxybh_W7QN"
      },
      "source": [
        "We build the **documents** and **queries** dictionaries if needed (or if the `FORCE_DICTIONARIES_REBUILD` flag is set to `True`).\n",
        "\n",
        "Documents and queries **vector embeddings** are also created, using the `Word2Vec` model trained on the documents' corpus.\n",
        "\n",
        "If the `REMAP_DOC_IDS` flag is set to `True`, document IDs are also **remapped to new IDs** to avoid gaps in the dictionary.\n",
        "\n",
        "We ultimately **save the dictionaries** into local files in the `DATA_FOLDER` directory."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cL166GSGW7QN"
      },
      "outputs": [],
      "source": [
        "# Check if the dictionaries need to be built/rebuilt\n",
        "if FORCE_DICTIONARIES_REBUILD or not os.path.exists(DATA_FOLDER + \"/docs_dict.json\") or not os.path.exists(DATA_FOLDER + \"/queries_dict.json\"):\n",
        "\n",
        "\tprint(\"The documents and queries dictionaries files do not exist, creating them...\")\n",
        "\n",
        "\t# Build a queries dictionary, containing the query_id as key, and as values both the query text and a list of associated relevant documents (as doc_id) taken from the scored documents (list of the 1000 relevant documents to the query)\n",
        "\tnumber_of_queries = MAX_DATASET_QUERIES if 0 < MAX_DATASET_QUERIES < dataset.queries_count() else dataset.queries_count()\n",
        "\tuse_scored_docs_for_relevant_documents = True\n",
        "\tfor query in tqdm(dataset.queries_iter(), \"Building the queries dictionary\", number_of_queries):\n",
        "\t\tif len(queries_dict) >= number_of_queries:\n",
        "\t\t\tbreak\n",
        "\t\tquery_id = query[IR_DATASET_COLS[\"QUERIES\"][\"id\"]]\n",
        "\t\tquery_text = query[IR_DATASET_COLS[\"QUERIES\"][\"text\"]]\n",
        "\t\tqueries_dict[query_id] = {\n",
        "\t\t\t\"text\": query_text,\n",
        "\t\t\t\"embedding\": None,\n",
        "\t\t\t\"relevant_docs\": []\n",
        "\t\t}\n",
        "\t# Add the relevant documents to the queries dictionary\n",
        "\tdoc_ids_with_rel = set()\n",
        "\t# First, add the relevant document(s) using the qrels (to ensure the most relevant documents are added first)\n",
        "\tfor qrel in tqdm(dataset.qrels_iter(), \"Adding relevant documents to queries (using qrels)\", dataset.qrels_count()):\n",
        "\t\tquery_id = qrel[IR_DATASET_COLS[\"QRELS\"][\"query_id\"]]\n",
        "\t\tif query_id not in queries_dict:\n",
        "\t\t\tcontinue\n",
        "\t\tdoc_id = qrel[IR_DATASET_COLS[\"QRELS\"][\"doc_id\"]]\n",
        "\t\tif NUMBER_OF_RELEVANT_DOCUMENTS_PER_QUERY < 0 or len(queries_dict[query_id][\"relevant_docs\"]) < NUMBER_OF_RELEVANT_DOCUMENTS_PER_QUERY:\n",
        "\t\t\tif doc_id not in queries_dict[query_id][\"relevant_docs\"]:\n",
        "\t\t\t\tqueries_dict[query_id][\"relevant_docs\"].append(doc_id)\n",
        "\t\t\t\tdoc_ids_with_rel.add(doc_id)\n",
        "\t# Then, add the relevant documents using the scoreddocs (if needed)\n",
        "\t# NOTE: the scoreddocs list contains 1000 relevant documents to the query, unordered and without an associated relevance score (these results are less precise than the qrels)\n",
        "\tif use_scored_docs_for_relevant_documents:\n",
        "\t\tfor scored_doc in tqdm(dataset.scoreddocs_iter(), \"Adding relevant documents to queries (using scoreddocs)\", dataset.scoreddocs_count()):\n",
        "\t\t\tquery_id = scored_doc[IR_DATASET_COLS[\"SCORED_DOCS\"][\"query_id\"]]\n",
        "\t\t\tif query_id not in queries_dict:\n",
        "\t\t\t\tcontinue\n",
        "\t\t\tdoc_id = scored_doc[IR_DATASET_COLS[\"SCORED_DOCS\"][\"doc_id\"]]\n",
        "\t\t\tif NUMBER_OF_RELEVANT_DOCUMENTS_PER_QUERY < 0 or len(queries_dict[query_id][\"relevant_docs\"]) < NUMBER_OF_RELEVANT_DOCUMENTS_PER_QUERY:\n",
        "\t\t\t\tif doc_id not in queries_dict[query_id][\"relevant_docs\"]:\n",
        "\t\t\t\t\tqueries_dict[query_id][\"relevant_docs\"].append(doc_id)\n",
        "\t\t\t\t\tdoc_ids_with_rel.add(doc_id)\n",
        "\t\t# Fix the missing relevant documents from the queries dictionary (if the relevant documents list was reduced)\n",
        "\t\tif NUMBER_OF_RELEVANT_DOCUMENTS_PER_QUERY > 0:\n",
        "\t\t\t# Re-add to the relevant documents list of each query all the removed documents that will be added to the documents dataset (i.e. in the doc_ids_with_rel set)\n",
        "\t\t\tfor scored_doc in tqdm(dataset.scoreddocs_iter(), \"Fixing missing relevant documents from queries dictionary\", dataset.scoreddocs_count()):\n",
        "\t\t\t\tquery_id = scored_doc[IR_DATASET_COLS[\"SCORED_DOCS\"][\"query_id\"]]\n",
        "\t\t\t\tif query_id not in queries_dict:\n",
        "\t\t\t\t\tcontinue\n",
        "\t\t\t\tdoc_id = scored_doc[IR_DATASET_COLS[\"SCORED_DOCS\"][\"doc_id\"]]\n",
        "\t\t\t\tif doc_id in doc_ids_with_rel and doc_id not in queries_dict[query_id][\"relevant_docs\"]:\n",
        "\t\t\t\t\tqueries_dict[query_id][\"relevant_docs\"].append(doc_id)\n",
        "\tprint(\n",
        "\t\tf\"Total number of documents relevant to at least one query: {len(doc_ids_with_rel)}\")\n",
        "\n",
        "\t# Initialize the corpus of documents (to be used to train the Word2Vec model)\n",
        "\tdocuments_corpus = []\n",
        "\n",
        "\t# Build a documents dictionary, containing the doc_id as key, and the attribute \"text\" containing the document text\n",
        "\tdocuments_count = 0\n",
        "\tdocuments_id_remapping = {}\n",
        "\tdocuments_id_remapping_inverse = {}\n",
        "\tfor doc in tqdm(dataset.docs_iter(), \"Building the documents dictionary\", dataset.docs_count()):\n",
        "\t\t# Add the document and its text to the documents dictionary\n",
        "\t\tdoc_id = doc[IR_DATASET_COLS[\"DOCS\"][\"id\"]]\n",
        "\t\tif doc_id not in doc_ids_with_rel:\n",
        "\t\t\tcontinue\n",
        "\t\tdoc_text = \"\"\n",
        "\t\tif USE_DOCUMENTS_DATASETS:\n",
        "\t\t\tdoc_text = doc[IR_DATASET_COLS[\"DOCS\"][\"title\"]] + \".\\n\" + doc[IR_DATASET_COLS[\"DOCS\"][\"body\"]]\n",
        "\t\telse:\n",
        "\t\t\tdoc_text = doc[IR_DATASET_COLS[\"DOCS\"][\"text\"]]\n",
        "\t\tdocs_dict[doc_id] = {\n",
        "\t\t\t\"text\": doc_text,\n",
        "\t\t\t\"embedding\": None\n",
        "\t\t}\n",
        "\t\t# Compute the remapped doc_id (if needed)\n",
        "\t\tif REMAP_DOC_IDS:\n",
        "\t\t\tnew_doc_id = str(documents_count)\n",
        "\t\t\tdocuments_id_remapping[doc_id] = new_doc_id\n",
        "\t\t\tdocuments_id_remapping_inverse[new_doc_id] = doc_id\n",
        "\t\t# Increment the documents count\n",
        "\t\tdocuments_count += 1\n",
        "\t\t# Add the document text to the corpus\n",
        "\t\tdocuments_corpus.append(get_preprocessed_text(doc_text).split(\" \"))\n",
        "\n",
        "\t# Load or train the Word2Vec model on the documents corpus\n",
        "\tload_or_train_word2vec_model(documents_corpus)\n",
        "\n",
        "\t# Scramble the documents and queries dictionaries\n",
        "\tif REMAP_DOC_IDS:\n",
        "\t\tprint(\"Scrambling the documents and queries dictionaries...\")\n",
        "\t\tdocs_dict = dict(random.sample(docs_dict.items(), len(docs_dict)))\n",
        "\t\tqueries_dict = dict(random.sample(queries_dict.items(), len(queries_dict)))\n",
        "\t\tprint(\"Scrambled the documents and queries dictionaries.\")\n",
        "\n",
        "\t# Iterate over documents in the dictionaries to compute the embeddings (and to eventually remap the doc_ids)\n",
        "\tnew_docs_dict = {}\n",
        "\tfor doc_id in tqdm(docs_dict, \"Computing document embeddings\" + (\" and remapping doc_ids\" if REMAP_DOC_IDS else \"\")):\n",
        "\t\t# Compute the embedding of the document text\n",
        "\t\tdocs_dict[doc_id][\"embedding\"] = word2vec_model.get_embedding((docs_dict[doc_id][\"text\"]))\n",
        "\t\t# Remap the doc_id (if needed)\n",
        "\t\tif REMAP_DOC_IDS:\n",
        "\t\t\tnew_docs_dict[documents_id_remapping[doc_id]] = {\n",
        "\t\t\t\t\"text\": docs_dict[doc_id][\"text\"],\n",
        "\t\t\t\t\"embedding\": docs_dict[doc_id][\"embedding\"]\n",
        "\t\t\t}\n",
        "\tif REMAP_DOC_IDS:\n",
        "\t\tdocs_dict = new_docs_dict\n",
        "\t# Iterate over queries in the dictionary to compute the embeddings (and to eventually remap the relevant doc_ids)\n",
        "\tfor query_id in tqdm(queries_dict, \"Computing query embeddings\" + (\" and remapping relevant doc_ids\" if REMAP_DOC_IDS else \"\")):\n",
        "\t\t# Compute the embedding of the query text\n",
        "\t\tqueries_dict[query_id][\"embedding\"] = word2vec_model.get_embedding(queries_dict[query_id][\"text\"])\n",
        "\t\t# Remap the relevant documents (if needed)\n",
        "\t\tif REMAP_DOC_IDS:\n",
        "\t\t\tcurrent_relevant_docs = queries_dict[query_id][\"relevant_docs\"]\n",
        "\t\t\tqueries_dict[query_id][\"relevant_docs\"] = [\n",
        "\t\t\t\tdocuments_id_remapping[doc_id] for doc_id in current_relevant_docs]\n",
        "\n",
        "\t# Print the total number of documents and queries\n",
        "\tprint(f\"Total number of documents (in built dict): {len(docs_dict)}\")\n",
        "\tprint(f\"Total number of queries (in built dict): {len(queries_dict)}\")\n",
        "\n",
        "\t# Save the 2 dictionaries to 2 JSON files in the \"data\" directory\n",
        "\tprint(\"Saving the documents and queries dictionaries to the JSON files...\")\n",
        "\twith open(DATA_FOLDER + \"/docs_dict.json\", \"w\") as docs_dict_file:\n",
        "\t\tjson.dump(docs_dict, docs_dict_file, indent=2)\n",
        "\twith open(DATA_FOLDER + \"/queries_dict.json\", \"w\") as queries_dict_file:\n",
        "\t\tjson.dump(queries_dict, queries_dict_file, indent=2)\n",
        "\tprint(\"Created the documents and queries dictionaries and saved them to the files.\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"2_3\"></a>\n",
        "\n",
        "## Dictionaries Loading"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2rsjYcc4W7QN"
      },
      "source": [
        "We load the `documents` and `queries` dictionaries from the local files in the `DATA_FOLDER` dicectory and save them to the corresponding dictionary variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RF1PLq9OW7QN"
      },
      "outputs": [],
      "source": [
        "# Load the documents and queries dictionaries from the JSON files\n",
        "print(\"Loading the documents and queries dictionaries from the files...\")\n",
        "with open(DATA_FOLDER + \"/docs_dict.json\", \"r\") as docs_dict_file:\n",
        "\tdocs_dict = json.load(docs_dict_file)\n",
        "print(f\"  Loaded {len(docs_dict)} documents\")\n",
        "with open(DATA_FOLDER + \"/queries_dict.json\", \"r\") as queries_dict_file:\n",
        "\tqueries_dict = json.load(queries_dict_file)\n",
        "print(f\"  Loaded {len(queries_dict)} queries\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SbIemImRW7QO"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"6\"></a>\n",
        "# ü§ñ Vision Transformer Model Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PnQDUoQ0W7QQ"
      },
      "source": [
        "In this section we implement 3 possible versions of a **Seq2Seq transformer model** to act as the final model for the evaluation of the **Differentiable Search Index** approach.\n",
        "\n",
        "The **Seq2Seq transformer models** are trained to generate a **sorted list of document IDs** in response to a given **query**.\n",
        "\n",
        "The 3 transformer models, described in detail in the sub-sections below, are:\n",
        "\n",
        "1. **Seq2Seq Transformer Model using _teacher forcing_**: A Seq2Seq transformer model trained using only the **teacher forcing** technique, no auto-regressive decoding is used during training.\n",
        "\n",
        "   At inference time, instead, the model uses an **auto-regressive decoding** technique to generate the sorted list of document IDs.\n",
        "\n",
        "2. **Seq2Seq Transformer Model using _auto-regressive decoding_**: A Seq2Seq transformer model trained using only the **auto-regressive decoding** technique, no teacher forcing is used during training.\n",
        "\n",
        "   This model also uses the same **auto-regressive decoding** technique at inference time to generate the sorted list of document IDs.\n",
        "\n",
        "3. **Seq2Seq Transformer Model using _scheduled sampling_**: A Seq2Seq transformer model trained using the **scheduled sampling** technique, which consists of training the model using a mix of teacher forcing and auto-regressive decoding, by using tokens taken from either the ground truth or the model's own predictions during training, based on a probability defined by the `scheduled_sampling_decay` hyperparameter.\n",
        "\n",
        "   Once again, the model uses only the **auto-regressive decoding** technique at inference time to generate the sorted list of document IDs."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDXB73GWW7QQ"
      },
      "outputs": [],
      "source": [
        "# Compute the max length of the document IDS\n",
        "if REMAP_DOC_IDS:\n",
        "\t# Doc IDs are remapped to a range [0, n_docs-1], so the max length depends on the number of documents\n",
        "\tdoc_ids_max_length = int(math.floor(math.log10(len(docs_dict))) + 1)\n",
        "else:\n",
        "\t# We calculate the max length of the doc IDs as the length of the longest doc ID\n",
        "\tdoc_ids_max_length = max([len(doc_id) for doc_id in docs_dict])\n",
        "\n",
        "# Number of output tokens for the encoded document IDs (the 10 digits [0-9] plus the special tokens, i.e. end of sequence, padding, start of sequence)\n",
        "output_tokens = 10 + 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Transformer Datasets Creation\n",
        "\n",
        "We create the **datasets** to train and evaluate the **Seq2Seq transformer models** using the `Seq2SeqDataset` class.\n",
        "\n",
        "Two different datasets are created:\n",
        "\n",
        "- **Indexing Dataset**: A dataset to train the model for the **indexing task**, in which the model learns to generate document IDs starting from **documents' text embeddings** as source sequences.\n",
        "\n",
        "   Items of the dataset have the form **`(encoded_document, encoded_doc_id)`** where `encoded_document` is the tokenized version of the document's text (i.e. a **vector of word token IDs** in the tokenizer's vocabulary), computed using a pretrained **BERT** model, and `encoded_doc_id` is a tokenized version of the document's ID in the documents dictionary, computed using an ad-hoc tokenizer which maps each digit of the document ID to an index (which is the same as the digit itself), and adds a special padding token, a special start-of-sequence token, and a special end-of-sequence token.\n",
        "\n",
        "- **Retrieval Dataset**: A dataset to train the model for the **retrieval task**, in which the model learns to generate document IDs starting from **queries' text embeddings** as source sequences.\n",
        "\n",
        "   Items of the dataset have the form **`(encoded_query, encoded_doc_id)`** where `encoded_query` is the tokenized version of the query's text, computed using the same **BERT** model, and `encoded_doc_id` is the tokenized version of the document's ID in the documents dictionary, computed using the same ad-hoc tokenizer used for the **Indexing Dataset**.\n",
        "\n",
        "Both datasets are shared among the 3 transformer models for training and evaluation."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ka5Kpp-kW7QR"
      },
      "outputs": [],
      "source": [
        "# Get the datasets for the transformer model (datasets are shared between the 3 transformer models)\n",
        "transformer_indexing_dataset = datasets.TransformerIndexingDataset(\n",
        "\tdocuments=docs_dict,\n",
        "\tdoc_id_max_length=doc_ids_max_length,\n",
        "\tdoc_max_length=TRANSFORMER_DOCUMENT_MAX_TOKENS,\n",
        "\tdataset_file_path=DATA_FOLDER + \"/transformer_indexing_dataset.json\",\n",
        "\tforce_dataset_rebuild=FORCE_DICTIONARIES_REBUILD)\n",
        "transformer_retrieval_dataset = datasets.TransformerRetrievalDataset(\n",
        "\tdocuments=docs_dict, queries=queries_dict,\n",
        "\tdoc_id_max_length=doc_ids_max_length,\n",
        "\tquery_max_length=TRANSFORMER_QUERY_MAX_TOKENS,\n",
        "\tdataset_file_path=DATA_FOLDER + \"/transformer_retrieval_dataset.json\",\n",
        "\tforce_dataset_rebuild=FORCE_DICTIONARIES_REBUILD)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SA70gEhTW7QR"
      },
      "source": [
        "We print some **examples** of the **Indexing Dataset** and the **Retrieval Dataset** to visualize the data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x1vRlp5yW7QR"
      },
      "outputs": [],
      "source": [
        "# Print some examples of the Transformers datasets\n",
        "print_dataset_examples = True\n",
        "if print_dataset_examples:\n",
        "\tprint(\"Example of a <encoded_doc, encoded_doc_id> pair:\")\n",
        "\tencoded_doc, encoded_doc_id = transformer_indexing_dataset[random.randint(\n",
        "\t\t0, len(transformer_indexing_dataset) - 1)]\n",
        "\tprint(\"  Encoded document:\\n  \", encoded_doc)\n",
        "\tprint(\"  Encoded document ID:\\n  \", encoded_doc_id)\n",
        "\tprint(\"Example of a <encoded_query, encoded_doc_id> pair:\")\n",
        "\tencoded_query, encoded_relevant_doc_id = transformer_retrieval_dataset[random.randint(\n",
        "\t\t0, len(transformer_retrieval_dataset) - 1)]\n",
        "\tprint(\"  Encoded query:\\n  \", encoded_query)\n",
        "\tprint(\"  Encoded relevant document ID:\\n  \", encoded_relevant_doc_id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Transformer Models Initialization & Training\n",
        "\n",
        "We create an auxiliary function to **initialize, train and evaluate** the **3 Seq2Seq transformer models**.\n",
        "\n",
        "The function considers the same constants and hyperparameters for all the Transformer model's different versions, with the exception of the parameters used for training.\n",
        "\n",
        "Each of the 3 Transformer models uses a different training approach (as explained in the introduction of this section), and then plots the training metrics (loss, accuracy, etc...) using the **Weights & Biases logger** for both training phases.\n",
        "\n",
        "Note that at inference time, in order to retrieve the top `K` most relevant documents, all the different Transformer models use the same **auto-regressive decoding** technique (generating document IDs' tokens one at a time, conditioning the generation of the next token on the previously generated tokens).\n",
        "\n",
        "For each model, we first train for the **indexing task**, using the `TransformerIndexingDataset` dataset, then train for the **retrieval task**, using the `TransformerRetrievalDataset` dataset (defined above).\n",
        "\n",
        "Before starting to train each model for the retrieval task, the retrieval dataset is split into a **training**, **validation** and **test** set: the latter is then used to evaluate the models' performance, thus for computing the **Mean Average Precision** and the **Recall at K**.\n",
        "\n",
        "For **computing the evaluation metrics**, we use a similar approach to the one used for the **Word2Vec** and **Siamese Network** models, but with the difference than in this case, while **training the model requires longer** than the previously described models (used as baselines), the **retrieval phase is significantly faster**, as the model directly optputs document IDs relevant to the query given as input, thus not requiring to compute the cosine similarity between the query and the entire documents corpus to find the top `K` most relevant documents."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D1eWfs5AW7QR"
      },
      "outputs": [],
      "source": [
        "def train_and_evaluate_dsi_transformer(transformer_type):\n",
        "\t''' Auxiliary function to train (or load checkpoints), show training results, and evaluate the transformer model of the given type '''\n",
        "\n",
        "\t# args to pass to the dsi transformer model\n",
        "\tuse_scheduled_sampling_decay = transformer_type == models.DSITransformer.TRANSFORMER_TYPES.SCHEDULED_SAMPLING_TRANSFORMER\n",
        "\tdsi_transformer_args = {\n",
        "\t\t\"tokens_in_vocabulary\": transformer_indexing_dataset.tokenizer.vocab_size,\n",
        "\t\t\"embeddings_size\": TRANSFORMER_EMBEDDINGS_SIZE,\n",
        "\t\t\"target_tokens\": output_tokens,\n",
        "\t\t\"transformer_heads\": 4,\n",
        "\t\t\"layers\": 3,\n",
        "\t\t\"dropout\": 0.2,\n",
        "\t\t\"learning_rate\": 0.001,\n",
        "\t\t\"batch_size\": 512,\n",
        "\t\t\"transformer_type\": transformer_type,\n",
        "\t\t\"scheduled_sampling_decay\": 0.01 if use_scheduled_sampling_decay else 0.0\n",
        "\t}\n",
        "\n",
        "\t# Initialize transformer model (using scheduled sampling)\n",
        "\ttransformer_model = models.DSITransformer(\n",
        "\t\t**dsi_transformer_args)\n",
        "\n",
        "\t# Model's checkpoint path\n",
        "\tmodel_type_string = \"\"\n",
        "\tif transformer_type == models.DSITransformer.TRANSFORMER_TYPES.SCHEDULED_SAMPLING_TRANSFORMER:\n",
        "\t\tmodel_type_string = \"scheduled_sampling\"\n",
        "\telif transformer_type == models.DSITransformer.TRANSFORMER_TYPES.AUTOREGRESSIVE_TRANSFORMER:\n",
        "\t\tmodel_type_string = \"autoregressive\"\n",
        "\telif transformer_type == models.DSITransformer.TRANSFORMER_TYPES.TEACHER_FORCINIG_TRANSFORMER:\n",
        "\t\tmodel_type_string = \"teacher_forcing\"\n",
        "\telse:\n",
        "\t\traise ValueError(\n",
        "\t\t\tf\"Invalid transformer type: {transformer_type}\")\n",
        "\tmodel_checkpoint_file = MODELS_FOLDER + \"/\" + model_type_string + \"_\" + MODEL_CHECKPOINT_FILE\n",
        "\n",
        "\t# Train the model or load its saved checkpoint\n",
        "\ttransformer_retrieval_test_set = None\n",
        "\ttransformer_retrieval_test_set_file = DATA_FOLDER + f\"/{model_type_string}_transformer_retrieval_test_set.json\"\n",
        "\tif LOAD_MODELS_CHECKPOINTS and os.path.exists(model_checkpoint_file):\n",
        "\t\t# Load the saved models checkpoint\n",
        "\t\tprint(\"A checkpoint for the model exist, loading the saved model checkpoint...\")\n",
        "\t\ttransformer_model = models.DSITransformer.load_from_checkpoint(\n",
        "\t\t\tmodel_checkpoint_file, **dsi_transformer_args)\n",
        "\t\tprint(\"Model checkpoint loaded.\")\n",
        "\t\t# Load the transformer retrieval test set from the JSON file\n",
        "\t\tprint(\"Loading the transformer retrieval test set from the JSON file...\")\n",
        "\t\twith open(transformer_retrieval_test_set_file, \"r\") as transformer_retrieval_test_set_file:\n",
        "\t\t\ttransformer_retrieval_test_set = json.load(\n",
        "\t\t\t\ttransformer_retrieval_test_set_file)\n",
        "\t\tprint(\"Transformer retrieval test set loaded.\")\n",
        "\telse:\n",
        "\t\t# Create 2 loggers for the transformer model (one for the indexing task and one for the retrieval task)\n",
        "\t\ttransformer_loggers = None\n",
        "\t\tif wandb_api is not None:\n",
        "\t\t\ttransformer_wandb_logger_indexing = WandbLogger(\n",
        "\t\t\t\tlog_model=\"all\", project=wandb_project, name=transformer_type + \" (Indexing)\")\n",
        "\t\t\ttransformer_wandb_logger_retrieval = WandbLogger(\n",
        "\t\t\t\tlog_model=\"all\", project=wandb_project, name=transformer_type + \" (Retrieval)\")\n",
        "\t\t\ttransformer_loggers = [transformer_wandb_logger_indexing,\n",
        "\t\t\t\t\t\t\t\t   transformer_wandb_logger_retrieval]\n",
        "\t\t# Train the transformer model (with scheduled sampling) for the indexing task\n",
        "\t\ttransformer_training_infos = training.train_transformer(\n",
        "\t\t\ttransformer_indexing_dataset=transformer_indexing_dataset,\n",
        "\t\t\ttransformer_retrieval_dataset=transformer_retrieval_dataset,\n",
        "\t\t\ttransformer_model=transformer_model,\n",
        "\t\t\tmax_epochs_list=[250, 150],\n",
        "\t\t\tbatch_size=transformer_model.hparams.batch_size,\n",
        "\t\t\tindexing_split_ratios=(1.0, 0.0),\n",
        "\t\t\tretrieval_split_ratios=(0.9, 0.05, 0.05),\n",
        "\t\t\tlogger=transformer_loggers,\n",
        "\t\t\tsave_path=model_checkpoint_file\n",
        "\t\t)\n",
        "\t\t# Show the wandb training run's dashboard\n",
        "\t\tif wandb_api is not None:\n",
        "\t\t\tindexing_run_id = transformer_training_infos[\"run_ids\"][\"indexing\"]\n",
        "\t\t\tif indexing_run_id is not None:\n",
        "\t\t\t\tprint(f\"Indexing training results for the {transformer_type} model:\")\n",
        "\t\t\t\tindexing_run_object: wandb_run.Run = wandb_api.run(\n",
        "\t\t\t\t\tf\"{wandb_entity}/{wandb_project}/{indexing_run_id}\")\n",
        "\t\t\t\tindexing_run_object.display(height=1000)\n",
        "\t\t\tretrieval_run_id = transformer_training_infos[\"run_ids\"][\"retrieval\"]\n",
        "\t\t\tif retrieval_run_id is not None:\n",
        "\t\t\t\tprint(f\"Retrieval training results for the {transformer_type} model:\")\n",
        "\t\t\t\tretrieval_run_object: wandb_run.Run = wandb_api.run(\n",
        "\t\t\t\t\tf\"{wandb_entity}/{wandb_project}/{retrieval_run_id}\")\n",
        "\t\t\t\tretrieval_run_object.display(height=1000)\n",
        "\t\t# Save the generated transformer retrieval test set to the JSON file\n",
        "\t\tprint(\"Saving the transformer retrieval test set to the JSON file...\")\n",
        "\t\tretrieval_test_dataset = transformer_training_infos[\"retrieval\"][\"test\"]\n",
        "\t\ttransformer_retrieval_test_set = {\n",
        "\t\t\t\"encoded_queries\": [],\n",
        "\t\t\t\"encoded_doc_ids\": []\n",
        "\t\t}\n",
        "\t\tretrieval_test_dataset_length = retrieval_test_dataset.__len__()\n",
        "\t\tfor i in range(retrieval_test_dataset_length):\n",
        "\t\t\tencoded_query, doc_id = retrieval_test_dataset.__getitem__(i)\n",
        "\t\t\ttransformer_retrieval_test_set[\"encoded_queries\"].append(\n",
        "\t\t\t\tencoded_query.tolist())\n",
        "\t\t\ttransformer_retrieval_test_set[\"encoded_doc_ids\"].append(\n",
        "\t\t\t\tdoc_id.tolist())\n",
        "\t\twith open(transformer_retrieval_test_set_file, \"w\") as transformer_retrieval_test_set_file:\n",
        "\t\t\tjson.dump(transformer_retrieval_test_set,\n",
        "\t\t\t\t\t  transformer_retrieval_test_set_file)\n",
        "\n",
        "\t# Evaluate the transformer model (for the retrieval task)\n",
        "\tif EVALUATE_MODELS:\n",
        "\t\ttransformer_retrieval_map_k = evaluation.compute_mean_average_precision_at_k(\n",
        "\t\t\tMODEL_TYPES.DSI_TRANSFORMER, queries_dict, docs_dict,\n",
        "\t\t\tk_documents=MAP_K, n_queries=MAP_N,\n",
        "\t\t\tprint_debug=PRINT_EVALUATION_DEBUG,\n",
        "\t\t\t# Keyword arguments for the Transformer model\n",
        "\t\t\tmodel=transformer_model, retrieval_dataset=transformer_retrieval_dataset, retrieval_test_set=transformer_retrieval_test_set)\n",
        "\t\ttransformer_retrieval_recall_k = evaluation.compute_recall_at_k(\n",
        "\t\t\tMODEL_TYPES.DSI_TRANSFORMER, queries_dict, docs_dict,\n",
        "\t\t\tk_documents=RECALL_K,\n",
        "\t\t\tprint_debug=PRINT_EVALUATION_DEBUG,\n",
        "\t\t\t# Keyword arguments for the Transformer model\n",
        "\t\t\tmodel=transformer_model, retrieval_dataset=transformer_retrieval_dataset, retrieval_test_set=transformer_retrieval_test_set)\n",
        "\t\tprint_model_evaluation_results(transformer_retrieval_map_k,\n",
        "\t\t\t\t\t\t\t\t\t   transformer_retrieval_recall_k)\n",
        "\n",
        "\treturn transformer_model, transformer_retrieval_map_k, transformer_retrieval_recall_k"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"6_1\"></a>\n",
        "\n",
        "## Teacher Forcing Seq2Seq Transformer Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AXT3FVMfW7QS"
      },
      "source": [
        "The first version of the **Seq2Seq transformer model** is trained using only the **teacher forcing** technique, no auto-regressive decoding is used during training.\n",
        "\n",
        "This means that, during training, the model is fed with the **ground truth** document IDs as target sequences, and is therefore trained to generate the correct document IDs given both the query and the ground truth document IDs as input.\n",
        "\n",
        "At inference time, the model uses the usual **auto-regressive decoding** technique to generate token logits (instead of probabilities, as no softmax is applied to the output of the Transformer model) for all possible document IDs tokens.\n",
        "\n",
        "We **train the model** and then, if a `WANDB_API_KEY` was provided, we also load the **Weights & Biases** dashboard to **plot the training results** for both the indexing and retrieval tasks (in this order).\n",
        "\n",
        "After training, we then evaluate the Transformer model by computing the usual **Mean Average Precision** (over `MAP_N` queries, each considering a precision at **K** of `MAP_K`) and the **Recall at K** (with **K** defined by `RECALL_K`) to **teacher forcing Seq2Seq transformer model**.\n",
        "\n",
        "We then **print the results** of the evaluation of both metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jML1dB2lW7QS"
      },
      "outputs": [],
      "source": [
        "# Train and evaluate the transformer model using only teacher forcing\n",
        "teacher_forcing_transformer, teacher_forcing_transformer_map_k, teacher_forcing_transformer_recall_k = \\\n",
        "\ttrain_and_evaluate_dsi_transformer(models.DSITransformer.TRANSFORMER_TYPES.TEACHER_FORCINIG_TRANSFORMER)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"6_1\"></a>\n",
        "\n",
        "## Autoregressive Seq2Seq Transformer Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ca6TF9hLW7QS"
      },
      "source": [
        "The second version of the **Seq2Seq transformer model** is trained using an **auto-regressive decoding** technique, no teacher forcing is used during training.\n",
        "\n",
        "This means that, during training, the model learns to generate the correct document IDs by relying only on its own predictions, and not on the ground truth document IDs.\n",
        "\n",
        "The same **auto-regressive decoding** technique is also used at inferencing time to generate token logits (instead of probabilities, as no softmax is applied to the output of the Transformer model) for all possible document IDs tokens.\n",
        "\n",
        "We **train the model** and then, if a `WANDB_API_KEY` was provided, we also load the **Weights & Biases** dashboard to **plot the training results** for both the indexing and retrieval tasks (in this order).\n",
        "\n",
        "After training, we then evaluate the Transformer model by computing the usual **Mean Average Precision** (over `MAP_N` queries, each considering a precision at **K** of `MAP_K`) and the **Recall at K** (with **K** defined by `RECALL_K`) to **teacher forcing Seq2Seq transformer model**.\n",
        "\n",
        "We then **print the results** of the evaluation of both metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dy6D3A0IW7QS"
      },
      "outputs": [],
      "source": [
        "# Train and evaluate the transformer model using ony an autoregressive approach\n",
        "autoregressive_transformer, autoregressive_transformer_map_k, autoregressive_transformer_recall_k = \\\n",
        "\ttrain_and_evaluate_dsi_transformer(models.DSITransformer.TRANSFORMER_TYPES.AUTOREGRESSIVE_TRANSFORMER)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "<a id=\"6_3\"></a>\n",
        "\n",
        "## Scheduled Sampling Seq2Seq Transformer Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NiE8BNHEW7QS"
      },
      "source": [
        "The final version of the **Seq2Seq transformer model** is trained using the **scheduled sampling** technique, which consists of training the model using a mix of teacher forcing and auto-regressive decoding, by using tokens taken from either the ground truth or the model's own predictions during training, based on a certain probability: this probability is initially set to 1.0 and then decays linearly over time, after each training epoch, by a factor defined by the `scheduled_sampling_decay` hyperparameter.\n",
        "\n",
        "During training, at each new token generation, the model decides whether to use the ground truth token (teacher forcing) or the previously generated token (autoregression) as input for the next token generation, based on the current probability.\n",
        "\n",
        "At inference time, only the **auto-regressive decoding** approach is used to generate token logits (instead of probabilities, as no softmax is applied to the output of the Transformer model) for all possible document IDs tokens.\n",
        "\n",
        "We **train the model** and then, if a `WANDB_API_KEY` was provided, we also load the **Weights & Biases** dashboard to **plot the training results** for both the indexing and retrieval tasks (in this order).\n",
        "\n",
        "After training, we then evaluate the Transformer model by computing the usual **Mean Average Precision** (over `MAP_N` queries, each considering a precision at **K** of `MAP_K`) and the **Recall at K** (with **K** defined by `RECALL_K`) to **teacher forcing Seq2Seq transformer model**.\n",
        "\n",
        "We then **print the results** of the evaluation of both metrics."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZQUIkSinW7QS"
      },
      "outputs": [],
      "source": [
        "# Train and evaluate the transformer model using scheduled sampling\n",
        "scheduled_sampling_transformer, scheduled_sampling_transformer_map_k, scheduled_sampling_transformer_recall_k = \\\n",
        "\ttrain_and_evaluate_dsi_transformer(models.DSITransformer.TRANSFORMER_TYPES.SCHEDULED_SAMPLING_TRANSFORMER)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
